{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, explode,substring, length, udf\n",
    "from pyspark.sql.types import DecimalType, StringType\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark is an custom SparkSession based on some config to work with Jupyter notebooks\n",
    "iv = spark.read.csv(\"hdfs://localhost:9000/user/lavish/data/investments.csv\"\n",
    "                , header='true'\n",
    "                , inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "startYear=1995\n",
    "endYear=2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company_permalink',\n",
       " 'company_name',\n",
       " 'company_category_list',\n",
       " 'company_country_code',\n",
       " 'company_state_code',\n",
       " 'company_region',\n",
       " 'company_city',\n",
       " 'investor_permalink',\n",
       " 'investor_name',\n",
       " 'investor_country_code',\n",
       " 'investor_state_code',\n",
       " 'investor_region',\n",
       " 'investor_city',\n",
       " 'funding_round_permalink',\n",
       " 'funding_round_type',\n",
       " 'funding_round_code',\n",
       " 'funded_at',\n",
       " 'raised_amount_usd']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredIV = iv.filter(iv.raised_amount_usd.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "splittedCategoryIV = filteredIV.select('raised_amount_usd',  substring('funded_at',-4,4).cast('int').alias('year')\n",
    "                       , split(col(\"company_category_list\")\n",
    "                       , \"[|]s*\").alias(\"categoryArr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "explodedIV=splittedCategoryIV.select('raised_amount_usd','year', explode('categoryArr').alias('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+-----------+\n",
      "|raised_amount_usd|year|   category|\n",
      "+-----------------+----+-----------+\n",
      "|        2000000.0|2008|Curated Web|\n",
      "|          41250.0|2014|      Games|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        3000000.0|2013|  Analytics|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        1700000.0|2013|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "+-----------------+----+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explodedIV.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "explodedIV.createOrReplaceTempView(\"investments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+-----------+\n",
      "|raised_amount_usd|year|   category|\n",
      "+-----------------+----+-----------+\n",
      "|        2000000.0|2008|Curated Web|\n",
      "|          41250.0|2014|      Games|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        3000000.0|2013|  Analytics|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        1700000.0|2013|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "|        1700000.0|2013|  Analytics|\n",
      "|        1700000.0|2013|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "|         150000.0|2014|     Mobile|\n",
      "|        1000050.0|2011|     Mobile|\n",
      "|        1000050.0|2011|     Mobile|\n",
      "|         150000.0|2014|     Mobile|\n",
      "+-----------------+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT * FROM investments\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLQUERY =  \"\"\"\n",
    "            SELECT CATEGORY, \n",
    "            CAST(YEAR AS INT), \n",
    "            SUM(RAISED_AMOUNT_USD) AS TOTAL, \n",
    "            CAST(SUM(RAISED_AMOUNT_USD) AS DECIMAL(30)) AS TOTAL_DEC \n",
    "            FROM INVESTMENTS GROUP \n",
    "            BY CATEGORY, YEAR \n",
    "            \"\"\"\n",
    "#  ORDER BY YEAR DESC, TOTAL DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----------------+----------+\n",
      "|            CATEGORY|YEAR|            TOTAL| TOTAL_DEC|\n",
      "+--------------------+----+-----------------+----------+\n",
      "|      Interest Graph|2011|           3.28E7|  32800000|\n",
      "|           Insurance|2015|  5.70529580149E9|5705295801|\n",
      "|  Big Data Analytics|2013|     2.35683979E9|2356839790|\n",
      "|           Aerospace|2014|4.6013734510098E8| 460137345|\n",
      "|               Audio|2005|          1.058E8| 105800000|\n",
      "|Cloud Infrastructure|2010|     1.38360796E8| 138360796|\n",
      "|    Cloud Management|2010|         5.4528E8| 545280000|\n",
      "|                Apps|2008|   6.3178257004E8| 631782570|\n",
      "| Insurance Companies|2015|    1.523851749E7|  15238517|\n",
      "|    Mobile Analytics|2010|          4.205E7|  42050000|\n",
      "|          Networking|2009|     5.39435025E8| 539435025|\n",
      "|               Local|2010|     1.50161942E8| 150161942|\n",
      "|Information Techn...|2000|     6.25112115E8| 625112115|\n",
      "|       Home & Garden|2007|         5.0605E8| 506050000|\n",
      "|        Ad Targeting|2010|       4.191857E8| 419185700|\n",
      "|Communications Ha...|2011|         5.5758E8| 557580000|\n",
      "|            Creative|2012|     1.65391911E8| 165391911|\n",
      "|               Women|2011|     1.00048667E8| 100048667|\n",
      "|      K-12 Education|2011|     1.81926358E8| 181926358|\n",
      "|   Online Scheduling|2012|         9.5505E7|  95505000|\n",
      "+--------------------+----+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(SQLQUERY)\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----------------+\n",
      "|            CATEGORY|FEATURES|            TOTAL|\n",
      "+--------------------+--------+-----------------+\n",
      "|      Interest Graph|[2011.0]|           3.28E7|\n",
      "|           Insurance|[2015.0]|  5.70529580149E9|\n",
      "|  Big Data Analytics|[2013.0]|     2.35683979E9|\n",
      "|           Aerospace|[2014.0]|4.6013734510098E8|\n",
      "|               Audio|[2005.0]|          1.058E8|\n",
      "|Cloud Infrastructure|[2010.0]|     1.38360796E8|\n",
      "|    Cloud Management|[2010.0]|         5.4528E8|\n",
      "|                Apps|[2008.0]|   6.3178257004E8|\n",
      "| Insurance Companies|[2015.0]|    1.523851749E7|\n",
      "|    Mobile Analytics|[2010.0]|          4.205E7|\n",
      "|          Networking|[2009.0]|     5.39435025E8|\n",
      "|               Local|[2010.0]|     1.50161942E8|\n",
      "|Information Techn...|[2000.0]|     6.25112115E8|\n",
      "|       Home & Garden|[2007.0]|         5.0605E8|\n",
      "|        Ad Targeting|[2010.0]|       4.191857E8|\n",
      "|Communications Ha...|[2011.0]|         5.5758E8|\n",
      "|            Creative|[2012.0]|     1.65391911E8|\n",
      "|               Women|[2011.0]|     1.00048667E8|\n",
      "|      K-12 Education|[2011.0]|     1.81926358E8|\n",
      "|   Online Scheduling|[2012.0]|         9.5505E7|\n",
      "+--------------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['YEAR'], outputCol = 'FEATURES')\n",
    "featureDF = vectorAssembler.transform(sqlDF).select('CATEGORY', 'FEATURES', 'TOTAL')\n",
    "\n",
    "featureDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = featureDF.select('CATEGORY').distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topCategories = [row.CATEGORY for row in f.collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for category in topCategories:\n",
    "    categoryDF=featureDF.filter(featureDF.CATEGORY == category)\n",
    "    if(categoryDF.count() > 10):\n",
    "        count +=1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryDF=featureDF.filter(featureDF.CATEGORY == 'Software')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'FEATURES', labelCol='TOTAL', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(f)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "\n",
    "for row in topCategoriesDFfrom1995.collect():    \n",
    "    if (row.CATEGORY in dict ):\n",
    "        dict[row.CATEGORY]['Y'].append(row.YEAR)\n",
    "        dict[row.CATEGORY]['T'].append(row.TOTAL)\n",
    "    else:\n",
    "        dict[row.CATEGORY] = { 'Y': [row.YEAR]  , 'T':[row.TOTAL]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
